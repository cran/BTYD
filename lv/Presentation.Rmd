---
title: "Modeling Customer Life and Transactions"
author: "Latentview Analytics"
date: "August 12, 2015"
output:
  slidy_presentation:
    highlight: tango
  beamer_presentation:
    colortheme: dolphin
    fonttheme: structurebold
    highlight: tango
    theme: AnnArbor
---

## Two Key Questions...

- How long will the customers remain alive?
- What is the net cash flow per period while alive

## Depends on the business settings

![](images/CustomerBases.png)


## Traditional Approaches

- There is no well established theory!
- The observed variables (e.g Recency, frequency, spend) are only imperfect indicators of
underlying behavioral characteristics.
- Different slices of data will yield different values of the variable and therefore different parameter estimates and different forecasts!

Challenges

- It is impossible to measure all the variables that determine an individuals buying behavior in any
setting.
- Buying behavior hence must be expressed in stochastic terms so as to take into account our ignorance(or lack
of data) regarding these determinants

## RFM Family of Models

Models use three variables: 

- Recency of purchases 
- Frequency of purchases 
- Monetary value of purchases

Used for non-contractual purchasing

Data needed: dates and amounts of purchases for individual customers


## Buy Till You Die Model

- Increase accuracy by looking at customer level data
- Transaction Process ("Buy")
    + while active, the number of transactions made by a customer follows a Poisson Process with a transaction rate
    + Transaction rates are distributed gamma across the population
- Dropout Process ("Die")
    + Each customer has an unobserved life time length, which is distributed exponential with a dropout rate
    + Dropout rates are distributed gamma across a population
- Approximates complexity in customer behaviour

## Gamma, Poisson & Expontential distributions

```{r echo=FALSE}
par(mfrow = c(2,2))
plot( dpois( x=0:20, lambda=1 ), type="b")
par(mfrow=c(1,1))
```

## Calibration and Holdout Period


## Example with Paypal Data

```{r, include=FALSE }
# Import the data and create the customer-by-time-matrix
# Get ready to model

##Install packages
toInstallCandidates <- c("ggplot2", "reshape2", "plyr", "lubridate", "devtools", "gsl")

# check if pkgs are already present

toInstall <- toInstallCandidates[!toInstallCandidates%in%library()$results[,1]] 
if(length(toInstall)!=0)
{install.packages(toInstall, repos = "http://cran.r-project.org")}

# load pkgs
lapply(toInstallCandidates, library, character.only = TRUE)


# Cleanup existing installation of BTYD
if ("package:BTYD" %in% search()) { detach("package:BTYD", unload=TRUE) }
if ("BTYD" %in% rownames(installed.packages())) { remove.packages("BTYD") }

#Change local to 1 if using the local version of BTYD instead of CRAN version
local <-1

if (local){
  devtools::install_github("jamespaul007/BTYD", ref="pnbd-fix")
} else{
  install.packages("BTYD")
}
library(BTYD)

elogFile <- "TxData.csv"
elog <- dc.ReadLines(elogFile, cust.idx = 1,
                     date.idx = 2, sales.idx = 3)
elog$date <- as.Date(elog$date, "%m/%d/%Y")
```


```{r, echo=TRUE}
head(elog, 10)
```

## Plot Sales across time

```{r, echo=FALSE}
qplot(date, sales, data = elog)
```

## Pre-processing

- Combine transactions on the same day
- Customer by Sufficient Matrix
    * x - Number of repeat transactions (Frequency)
    * t.x - Number of recent repeat transactions
    * T.cal - Length of calibration period
- Customer by Time Matrix
    * 

```{r, include=FALSE} 
T.cal <- as.Date("2013-12-31")
simData <- dc.ElogToCbsCbt(elog, per="week", T.cal)
cal.cbs <- simData$cal$cbs
cal.cbt <- simData$cal$cbt

# for Holdout period
hold.cbs <- simData$holdout$cbs
head(hold.cbs)
hold.cbt <- simData$holdout$cbt
```

## Customer by Sufficient Matrix

```{r, echo=TRUE}
head(cal.cbs)
```

## Customer by Time Matrix

```{r, echo=TRUE}
head(cal.cbt)
```

## Estimate Parameters

```{r, echo=FALSE}
params <- pnbd.EstimateParameters(cal.cbs)
params

LL <- pnbd.cbs.LL(params, cal.cbs);
LL
```

## It's converging

```{r, echo=FALSE}
p.matrix <- c(params, LL);
for (i in 1:2){
  params <- pnbd.EstimateParameters(cal.cbs, params);
  LL <- pnbd.cbs.LL(params, cal.cbs);
  p.matrix.row <- c(params, LL);
  p.matrix <- rbind(p.matrix, p.matrix.row);
}
colnames(p.matrix) <- c("r", "alpha", "s", "beta", "LL");
rownames(p.matrix) <- 1:3;
p.matrix;

```

## Heterogeneity in Transaction rates

```{r, echo=FALSE}
pnbd.PlotTransactionRateHeterogeneity(params)
```

## Heterogeneity in Dropout rates

```{r, echo=FALSE}
pnbd.PlotDropoutRateHeterogeneity(params)
```

## Individual level estimations

```{r, echo=TRUE}
pnbd.Expectation(params, t=52)
```

## Expected behavior from a particular customer

```{r, echo=FALSE}
custName <- sample(cal.cbs[,1],1)
custName

cal.cbs[custName,]

x<-cal.cbs[custName,"x"]
t.x <-cal.cbs[custName,"t.x"]
T.cal <- cal.cbs[custName,"T.cal"]

pnbd.ConditionalExpectedTransactions(params, T.star = 52, x, t.x, T.cal)
pnbd.PAlive(params, x, t.x, T.cal)
```

# Visualize the distribution of P(Alive) across customers
```{r, echo=FALSE}
p.alives <- pnbd.PAlive(params, cal.cbs[,"x"], cal.cbs[,"t.x"], cal.cbs[,"T.cal"])

ggplot(as.data.frame(p.alives),aes(x=p.alives))+
  geom_histogram(colour="grey",fill="orange")+
  ylab("Number of Customers")+
  xlab("Probability Customer is 'Live'")+
  theme_minimal()
```

## Goodness of Fit

```{r, echo=FALSE}
censor <- 7
pnbd.PlotFrequencyInCalibration(params, cal.cbs, censor)
```

## Verify in Holdout Period

```{r, echo=FALSE}
x.star <- hold.cbs[,"x.star"]
comp <- pnbd.PlotFreqVsConditionalExpectedFrequency(params, T.star=52, cal.cbs, x.star, censor)
rownames(comp) <- c("act", "exp", "bin")
comp

pnbd.PlotRecVsConditionalExpectedFrequency(params, cal.cbs, T.star=52, x.star)
```

## Plot Actual V/s Expected Transactions on a weekly basis

```{r, echo=FALSE}
tot.cbt <- dc.CreateFreqCBT(elog)
head(tot.cbt)

# ...Completed Freq CBT
d.track.data <- rep(0, 7 * 105)
origin <- as.Date("2013-01-01")
for (i in colnames(tot.cbt)){
  date.index <- difftime(as.Date(i), origin) + 1;
  d.track.data[date.index] <- sum(tot.cbt[,i]);
}
w.track.data <- rep(0, 105)
for (j in 1:105){
  w.track.data[j] <- sum(d.track.data[(j*7-6):(j*7)])
}
```

## Plot Cumulative Actual V/s Expected Transactions 

```{r, echo=FALSE}
T.cal <- cal.cbs[,"T.cal"]
T.tot <- 105
n.periods.final <- 105
inc.tracking <- pnbd.PlotTrackingInc(params, T.cal,
                                     T.tot, w.track.data,
                                     n.periods.final)
inc.tracking[,20:25]

cum.tracking.data <- cumsum(w.track.data)
cum.tracking <- pnbd.PlotTrackingCum(params, T.cal,
                                     T.tot, cum.tracking.data,
                                     n.periods.final)
cum.tracking[,20:25]
```


